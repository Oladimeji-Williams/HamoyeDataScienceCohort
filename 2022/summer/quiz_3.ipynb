{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ef404d2",
   "metadata": {},
   "source": [
    "# Stage C Quiz Solution\n",
    "\n",
    "Oladimeji Williams\n",
    "© ellipsis\n",
    "\n",
    "---\n",
    "\n",
    "I **Oladimeji WILLIAMS**, confirm - by submitting this document - that the solutions in this notebook are a result of my own work and that I abide by the [Code of Conduct](https://drive.google.com/file/d/1sbR80aowp1daCnElwx3kNm0fxids0e6b/view) contained therein.\n",
    "\n",
    "\n",
    "### Overview: Machine Learning: Classification -  Managing the Quality Metric of Global Ecological Footprint\n",
    "> The dataset for the remainder of this quiz is the Stability of the Grid System data [here](https://archive.ics.uci.edu/ml/machine-learning-databases/00471/Data_for_UCI_named.csv). Electrical grids require a balance between electricity supply and demand in order to be stable. Conventional systems achieve this balance through demand-driven electricity production. For future grids with a high share of inflexible (i.e., renewable) energy sources, the concept of demand response is a promising solution. This implies changes in electricity consumption in relation to electricity price changes. In this work, we’ll build a binary classification model to predict if a grid is stable or unstable using the UCI Electrical Grid Stability Simulated dataset.\n",
    "\n",
    "It has 12 primary predictive features and two dependent variables.\n",
    "\n",
    "Predictive features:\n",
    "\n",
    "1. `'tau1'` to `'tau4'`: the reaction time of each network participant, a real value within the range 0.5 to 10 ('tau1' corresponds to the supplier node, 'tau2' to 'tau4' to the consumer nodes);\n",
    "2. `'p1'` to `'p4'`: nominal power produced (positive) or consumed (negative) by each network participant, a real value within the range -2.0 to -0.5 for consumers ('p2' to 'p4'). As the total power consumed equals the total power generated, p1 (supplier node) = - (p2 + p3 + p4);\n",
    "3. `'g1'` to `'g4'`: price elasticity coefficient for each network participant, a real value within the range 0.05 to 1.00 ('g1' corresponds to the supplier node, 'g2' to 'g4' to the consumer nodes; 'g' stands for 'gamma');\n",
    "\n",
    "Dependent variables:\n",
    "\n",
    "1. `'stab'`: the maximum real part of the characteristic differential equation root (if positive, the system is linearly unstable; if negative, linearly stable);\n",
    "2. `'stabf'`: a categorical (binary) label (`'stable'` or `'unstable'`).\n",
    "\n",
    "\n",
    "Because of the direct relationship between 'stab' and 'stabf' ('stabf' = 'stable' if 'stab' <= 0, 'unstable' otherwise), 'stab' should be dropped and 'stabf' will remain as the sole dependent variable (binary classification).\n",
    "\n",
    "Split the data into an 80-20 train-test split with a random state of “1”. Use the standard scaler to transform the train set (x_train, y_train) and the test set (x_test). Use scikit learn to train a random forest and extra trees classifier. And use xgboost and lightgbm to train an extreme boosting model and a light gradient boosting model. Use random_state = 1 for training all models and evaluate on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b8bea9",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0af817f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load All Possible Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.metrics import recall_score, accuracy_score, precision_score, f1_score, confusion_matrix\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "855c08e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dateset\n",
    "df = pd.read_csv('Data_for_UCI_named.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6789b222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the dataset into another dataframe\n",
    "df_copy = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6188363b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tau1</th>\n",
       "      <th>tau2</th>\n",
       "      <th>tau3</th>\n",
       "      <th>tau4</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>g1</th>\n",
       "      <th>g2</th>\n",
       "      <th>g3</th>\n",
       "      <th>g4</th>\n",
       "      <th>stab</th>\n",
       "      <th>stabf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.959060</td>\n",
       "      <td>3.079885</td>\n",
       "      <td>8.381025</td>\n",
       "      <td>9.780754</td>\n",
       "      <td>3.763085</td>\n",
       "      <td>-0.782604</td>\n",
       "      <td>-1.257395</td>\n",
       "      <td>-1.723086</td>\n",
       "      <td>0.650456</td>\n",
       "      <td>0.859578</td>\n",
       "      <td>0.887445</td>\n",
       "      <td>0.958034</td>\n",
       "      <td>0.055347</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.304097</td>\n",
       "      <td>4.902524</td>\n",
       "      <td>3.047541</td>\n",
       "      <td>1.369357</td>\n",
       "      <td>5.067812</td>\n",
       "      <td>-1.940058</td>\n",
       "      <td>-1.872742</td>\n",
       "      <td>-1.255012</td>\n",
       "      <td>0.413441</td>\n",
       "      <td>0.862414</td>\n",
       "      <td>0.562139</td>\n",
       "      <td>0.781760</td>\n",
       "      <td>-0.005957</td>\n",
       "      <td>stable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.971707</td>\n",
       "      <td>8.848428</td>\n",
       "      <td>3.046479</td>\n",
       "      <td>1.214518</td>\n",
       "      <td>3.405158</td>\n",
       "      <td>-1.207456</td>\n",
       "      <td>-1.277210</td>\n",
       "      <td>-0.920492</td>\n",
       "      <td>0.163041</td>\n",
       "      <td>0.766689</td>\n",
       "      <td>0.839444</td>\n",
       "      <td>0.109853</td>\n",
       "      <td>0.003471</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.716415</td>\n",
       "      <td>7.669600</td>\n",
       "      <td>4.486641</td>\n",
       "      <td>2.340563</td>\n",
       "      <td>3.963791</td>\n",
       "      <td>-1.027473</td>\n",
       "      <td>-1.938944</td>\n",
       "      <td>-0.997374</td>\n",
       "      <td>0.446209</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.929381</td>\n",
       "      <td>0.362718</td>\n",
       "      <td>0.028871</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.134112</td>\n",
       "      <td>7.608772</td>\n",
       "      <td>4.943759</td>\n",
       "      <td>9.857573</td>\n",
       "      <td>3.525811</td>\n",
       "      <td>-1.125531</td>\n",
       "      <td>-1.845975</td>\n",
       "      <td>-0.554305</td>\n",
       "      <td>0.797110</td>\n",
       "      <td>0.455450</td>\n",
       "      <td>0.656947</td>\n",
       "      <td>0.820923</td>\n",
       "      <td>0.049860</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tau1      tau2      tau3      tau4        p1        p2        p3  \\\n",
       "0  2.959060  3.079885  8.381025  9.780754  3.763085 -0.782604 -1.257395   \n",
       "1  9.304097  4.902524  3.047541  1.369357  5.067812 -1.940058 -1.872742   \n",
       "2  8.971707  8.848428  3.046479  1.214518  3.405158 -1.207456 -1.277210   \n",
       "3  0.716415  7.669600  4.486641  2.340563  3.963791 -1.027473 -1.938944   \n",
       "4  3.134112  7.608772  4.943759  9.857573  3.525811 -1.125531 -1.845975   \n",
       "\n",
       "         p4        g1        g2        g3        g4      stab     stabf  \n",
       "0 -1.723086  0.650456  0.859578  0.887445  0.958034  0.055347  unstable  \n",
       "1 -1.255012  0.413441  0.862414  0.562139  0.781760 -0.005957    stable  \n",
       "2 -0.920492  0.163041  0.766689  0.839444  0.109853  0.003471  unstable  \n",
       "3 -0.997374  0.446209  0.976744  0.929381  0.362718  0.028871  unstable  \n",
       "4 -0.554305  0.797110  0.455450  0.656947  0.820923  0.049860  unstable  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Peak the first few observations of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d16c22e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tau1     float64\n",
       "tau2     float64\n",
       "tau3     float64\n",
       "tau4     float64\n",
       "p1       float64\n",
       "p2       float64\n",
       "p3       float64\n",
       "p4       float64\n",
       "g1       float64\n",
       "g2       float64\n",
       "g3       float64\n",
       "g4       float64\n",
       "stab     float64\n",
       "stabf     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Peak the datatypes\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c965873d",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b1300a",
   "metadata": {},
   "source": [
    "`TN` = **98%**, `FP` = **2%**, `FN` = **18%**, `TP` = **82%**\n",
    "This satisfies both the recall rate and false positive rate values.\n",
    "And it is the option with the least `False Positive` which gives the minimum business costs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6e31e3",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d8fe31",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "F1 Score = \\frac {2TP}{2TP  +  FP  +  FN}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "F1 Score = \\frac {(2 * 255)}{(2 * 255) + 1380 + 45}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "F1 Score = 0.2635\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150c09af",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ea649c4d",
   "metadata": {},
   "source": [
    "overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ac88a1",
   "metadata": {},
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "raw",
   "id": "10058811",
   "metadata": {},
   "source": [
    "RMSE Value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5249e6ef",
   "metadata": {},
   "source": [
    "## Question 5"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4a3bbad8",
   "metadata": {},
   "source": [
    "To populate the decision stump\n",
    "To make the algorithm stronger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e151bded",
   "metadata": {},
   "source": [
    "## Question 6"
   ]
  },
  {
   "cell_type": "raw",
   "id": "02f76745",
   "metadata": {},
   "source": [
    "Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fa83a0",
   "metadata": {},
   "source": [
    "## Question 7"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e2204e4e",
   "metadata": {},
   "source": [
    "Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18197785",
   "metadata": {},
   "source": [
    "## Question 8"
   ]
  },
  {
   "cell_type": "raw",
   "id": "086879c2",
   "metadata": {},
   "source": [
    "The model has no discrimination capacity to differentiate between the positive and the negative class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a5b3f4",
   "metadata": {},
   "source": [
    "## Question 9"
   ]
  },
  {
   "cell_type": "raw",
   "id": "47b3a9ce",
   "metadata": {},
   "source": [
    "8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b1d9ac",
   "metadata": {},
   "source": [
    "## Question 10"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a95ae107",
   "metadata": {},
   "source": [
    "Generate synthetic samples/data using SMOTE\n",
    "Use Bagging method\n",
    "Collect more data for the positive case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc85609",
   "metadata": {},
   "source": [
    "## Question 11"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8aa06272",
   "metadata": {},
   "source": [
    "One-hot encoding\n",
    "Use integer values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77fed14",
   "metadata": {},
   "source": [
    "## Question 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf549eb",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "entropy = -\\frac{3}{7}log(\\frac{3}{7})\\ -\\ \\frac{4}{7}log(\\frac{4}{7})\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e431b888",
   "metadata": {},
   "source": [
    "## Question 13"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9dad083d",
   "metadata": {},
   "source": [
    "Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d279883b",
   "metadata": {},
   "source": [
    "## Question 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86a26e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.9167\n"
     ]
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "X = df.drop(columns= [\"stab\", \"stabf\"])\n",
    "y = df[\"stabf\"]\n",
    "y_encoded = encoder.fit_transform(y)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.3, random_state=0)\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(x_train, y_train)\n",
    "print(f\"Accuracy on test set: {round(rf.score(x_test, y_test), 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f264c94a",
   "metadata": {},
   "source": [
    "## Question 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba3709ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.9373\n"
     ]
    }
   ],
   "source": [
    "xgboost = XGBClassifier()\n",
    "xgboost.fit(x_train, y_train)\n",
    "print(f\"Accuracy on test set: {round(xgboost.score(x_test, y_test), 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e6372d",
   "metadata": {},
   "source": [
    "## Question 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94604784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.9353\n"
     ]
    }
   ],
   "source": [
    "lgbm = LGBMClassifier()\n",
    "lgbm.fit(x_train, y_train)\n",
    "print(f\"Accuracy on test set: {round(lgbm.score(x_test, y_test), 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099805ed",
   "metadata": {},
   "source": [
    "## Question 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f309b2ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 300, 'min_samples_split': 2, 'min_samples_leaf': 8, 'max_features': None}\n"
     ]
    }
   ],
   "source": [
    "xtree = ExtraTreesClassifier()\n",
    "xtree.fit(x_train, y_train)\n",
    "param_grid1 = {\n",
    "    \"n_estimators\": [100, 300, 500, 1000],\n",
    "    \"min_samples_split\": [2, 5, 7, 10],\n",
    "    \"min_samples_leaf\": [4, 6, 8, 16],\n",
    "    \"max_features\": [\"auto\", \"log2\", None]\n",
    "}\n",
    "cv = RandomizedSearchCV(estimator=xtree, param_distributions=param_grid1, cv=5, n_iter=10, scoring=\"accuracy\", n_jobs=-1, verbose=-1, random_state=1)\n",
    "cv.fit(x_train, y_train)\n",
    "print(cv.best_params_)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "69cbe523",
   "metadata": {},
   "source": [
    "N_estimators = 1000 , min_samples_split = 2 , min_samples_leaf = 8, max_features = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e8a209",
   "metadata": {},
   "source": [
    "## Question 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d77ab5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.9207\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy on test set: {round(xtree.score(x_test, y_test), 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce02dd4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.92\n"
     ]
    }
   ],
   "source": [
    "xtree2 = ExtraTreesClassifier(n_estimators = 1000 , min_samples_split = 2 , min_samples_leaf = 8, max_features = None, random_state=1)\n",
    "xtree2.fit(x_train, y_train)\n",
    "print(f\"Accuracy on test set: {round(xtree2.score(x_test, y_test), 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82fcf95",
   "metadata": {},
   "source": [
    "## Question 19"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a796220a",
   "metadata": {},
   "source": [
    "Bayesian optimization\n",
    "Grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb627aa",
   "metadata": {},
   "source": [
    "## Question 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "376518e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max: weights    tau2\n",
      "dtype: object\n",
      "min: weights    p1\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "weights_xtree = pd.DataFrame(data={\"weights\":xtree.feature_importances_}, index=x_train.columns)\n",
    "print(f\"max: {weights_xtree.idxmax()}\")\n",
    "print(f\"min: {weights_xtree.idxmin()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2068fa26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
